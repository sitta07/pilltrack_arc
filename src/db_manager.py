import pickle
import json
import os
from datetime import datetime

class DBManager:
    @staticmethod
    def load_pkl(path):
        """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Vector Database (.pkl)"""
        if os.path.exists(path):
            with open(path, 'rb') as f: return pickle.load(f)
        return {}

    @staticmethod
    def save_pkl(data, path):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÑ‡∏ü‡∏•‡πå Vector Database (.pkl)"""
        with open(path, 'wb') as f:
            pickle.dump(data, f)

    # ‚úÖ [NEW] ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏û‡∏£‡∏∞‡πÄ‡∏≠‡∏Å: ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡∏ö Hybrid
    @staticmethod
    def insert_data(db, name, dino_vec, sift_des):
        """
        ‡πÅ‡∏ó‡∏£‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á Database ‡πÇ‡∏î‡∏¢‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ (‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Schema ‡πÉ‡∏´‡πâ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥)
        Structure ‡πÉ‡∏´‡∏°‡πà: 
        {
            "Para_pack_1": {
                "dino": [vec1, vec2, ...],
                "sift": [des1, des2, ...]
            }
        }
        """
        # 1. ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡∏ô‡∏µ‡πâ ‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≠
        if name not in db:
            db[name] = {"dino": [], "sift": []}
        
        # 2. (Migration Support) ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡πÄ‡∏à‡∏≠‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô List ‡∏•‡πâ‡∏ß‡∏ô ‡πÉ‡∏´‡πâ‡πÅ‡∏õ‡∏•‡∏á‡∏£‡πà‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô
        if isinstance(db[name], list):
            print(f"üì¶ Converting legacy format for {name}...")
            db[name] = {"dino": db[name], "sift": []}

        # 3. ‡∏¢‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡∏á‡∏ñ‡∏±‡∏á
        db[name]["dino"].append(dino_vec)
        
        # SIFT descriptors ‡∏≠‡∏≤‡∏à‡πÄ‡∏õ‡πá‡∏ô None ‡πÑ‡∏î‡πâ (‡∏ñ‡πâ‡∏≤‡∏†‡∏≤‡∏û‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏∏‡∏î‡πÄ‡∏î‡πà‡∏ô)
        if sift_des is not None:
            db[name]["sift"].append(sift_des)

    @staticmethod
    def get_unique_drugs(db_dict):
        """‡∏™‡∏Å‡∏±‡∏î‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏¢‡∏≤‡∏à‡∏≤‡∏Å‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡πÉ‡∏ô pkl"""
        names = set()
        for k in db_dict.keys():
            # Logic ‡∏ï‡∏±‡∏î‡∏Ñ‡∏≥‡∏ß‡πà‡∏≤ _pack ‡∏≠‡∏≠‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÑ‡∏î‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏¢‡∏≤‡πÄ‡∏û‡∏µ‡∏¢‡∏ß‡πÜ
            if "_pack" in k: 
                names.add(k.split('_pack')[0])
            else:
                names.add(k) # ‡∏Å‡∏£‡∏ì‡∏µ‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ _pack
        return sorted(list(names))

    @staticmethod
    def generate_metadata(drug_names, out_path):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå Metadata JSON ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Raspberry Pi"""
        metadata = {
            "drugs": drug_names,
            "updated_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "total": len(drug_names)
        }
        with open(out_path, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=4, ensure_ascii=False)

    @staticmethod
    def add_log(event_type, drug_name="-", count=0, details="-"):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô (Audit Trail)"""
        log_path = "database/activity_log.json"
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå database ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
        os.makedirs(os.path.dirname(log_path), exist_ok=True)
        
        log_entry = {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "event": event_type,
            "drug": drug_name,
            "images": count,
            "details": details
        }
        
        logs = []
        if os.path.exists(log_path):
            try:
                with open(log_path, 'r', encoding='utf-8') as f:
                    logs = json.load(f)
            except: logs = []
        
        logs.insert(0, log_entry)
        with open(log_path, 'w', encoding='utf-8') as f:
            json.dump(logs[:100], f, indent=4, ensure_ascii=False)

    @staticmethod
    def get_logs():
        """‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ Log ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏≠‡∏≠‡∏Å‡∏°‡∏≤‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•"""
        log_path = "database/activity_log.json"
        if os.path.exists(log_path):
            try:
                with open(log_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except: return []
        return []